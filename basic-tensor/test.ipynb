{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[3 6]\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<bound method BaseSession.close of <tensorflow.python.client.session.Session object at 0x000001C1939286A0>>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a=tf.constant([1, 2], name=\"a\")\n",
    "b=tf.constant([2, 4], name=\"b\")\n",
    "\n",
    "result = a+b\n",
    "session=tf.Session()\n",
    "print(session.run(result))\n",
    "session.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[-0.11131823  2.3845987 ]]\n[[-0.11131823  2.3845987 ]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1, 2], stddev=1, seed=1))\n",
    "x = tf.placeholder(tf.float32, shape=(1, 2))\n",
    "x1 = tf.constant([[0.7, 0.9]])\n",
    "\n",
    "a = x + w1\n",
    "b = x1 + w1\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "y_1 = session.run(a, feed_dict={x: [[0.7, 0.9]]})\n",
    "y_2 = session.run(b)\n",
    "\n",
    "print(y_1)\n",
    "print(y_2)\n",
    "\n",
    "session.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "list_of_points1_ = [[1,2], [3,4], [5,6], [7,8]]\n",
    "list_of_points2_ = [[15,16], [13,14], [11,12], [9,10]]\n",
    "\n",
    "list_of_points1 = np.array([np.array(elem).reshape(1,2) for elem in list_of_points1_])\n",
    "list_of_points2 = np.array([np.array(elem).reshape(1,2) for elem in list_of_points2_])\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    point1 = tf.placeholder(tf.float32, shape=(1, 2))\n",
    "    point2 = tf.placeholder(tf.float32, shape=(1, 2))\n",
    "\n",
    "    def calculate_distance(point1, point2):\n",
    "        difference = tf.subtract(point1, point2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n [-2.4427042   0.0992484   0.5912243 ]]\n[[-0.8113182 ]\n [ 1.4845988 ]\n [ 0.06532937]]\n在迭代 0 次后， 训练损失为 0.309702\n",
      "在迭代 100 次后， 训练损失为 0.226883\n在迭代 200 次后， 训练损失为 0.168065\n",
      "在迭代 300 次后， 训练损失为 0.125657\n在迭代 400 次后， 训练损失为 0.0981408\n在迭代 500 次后， 训练损失为 0.0795618",
      "\n",
      "在迭代 600 次后， 训练损失为 0.0661165\n在迭代 700 次后， 训练损失为 0.0567442\n在迭代 800 次后， 训练损失为 0.0492548\n在迭代 900 次后， 训练损失为 0.0436001\n在迭代 1000 次后， 训练损失为 0.0393322",
      "\n",
      "在迭代 1100 次后， 训练损失为 0.0359915\n在迭代 1200 次后， 训练损失为 0.0329835\n在迭代 1300 次后， 训练损失为 0.0303536\n在迭代 1400 次后， 训练损失为 0.02774",
      "\n在迭代 1500 次后， 训练损失为 0.0251878\n在迭代 1600 次后， 训练损失为 0.0230731",
      "\n在迭代 1700 次后， 训练损失为 0.0213115\n在迭代 1800 次后， 训练损失为 0.0199283\n在迭代 1900 次后， 训练损失为 0.0186917\n",
      "在迭代 2000 次后， 训练损失为 0.0173816\n在迭代 2100 次后， 训练损失为 0.0161431\n在迭代 2200 次后， 训练损失为 0.0152546",
      "\n在迭代 2300 次后， 训练损失为 0.0144568\n在迭代 2400 次后， 训练损失为 0.0136115\n在迭代 2500 次后， 训练损失为 0.012777\n在迭代 2600 次后， 训练损失为 0.012127",
      "\n在迭代 2700 次后， 训练损失为 0.0115986\n",
      "在迭代 2800 次后， 训练损失为 0.0111288\n在迭代 2900 次后， 训练损失为 0.0106995\n在迭代 3000 次后， 训练损失为 0.0102881\n在迭代 3100 次后， 训练损失为 0.00986256\n在迭代 3200 次后， 训练损失为 0.00941892\n",
      "在迭代 3300 次后， 训练损失为 0.00905516\n在迭代 3400 次后， 训练损失为 0.00867567\n",
      "在迭代 3500 次后， 训练损失为 0.00827888\n在迭代 3600 次后， 训练损失为 0.00794147\n在迭代 3700 次后， 训练损失为 0.00760578\n在迭代 3800 次后， 训练损失为 0.00732986\n",
      "在迭代 3900 次后， 训练损失为 0.00705005\n",
      "在迭代 4000 次后， 训练损失为 0.00676341\n在迭代 4100 次后， 训练损失为 0.00646802\n在迭代 4200 次后， 训练损失为 0.00616837\n在迭代 4300 次后， 训练损失为 0.00589329\n",
      "在迭代 4400 次后， 训练损失为 0.00565545\n在迭代 4500 次后， 训练损失为 0.00541408\n",
      "在迭代 4600 次后， 训练损失为 0.0051715\n在迭代 4700 次后， 训练损失为 0.00494413\n在迭代 4800 次后， 训练损失为 0.00474756\n在迭代 4900 次后， 训练损失为 0.00460955",
      "\n",
      "在迭代 5000 次后， 训练损失为 0.00446996\n在迭代 5100 次后， 训练损失为 0.00431918\n在迭代 5200 次后， 训练损失为 0.00416556\n在迭代 5300 次后， 训练损失为 0.00400994\n在迭代 5400 次后， 训练损失为 0.00385165",
      "\n在迭代 5500 次后， 训练损失为 0.00369193\n",
      "在迭代 5600 次后， 训练损失为 0.00352966\n在迭代 5700 次后， 训练损失为 0.00336364\n在迭代 5800 次后， 训练损失为 0.00319565\n在迭代 5900 次后， 训练损失为 0.0030865\n",
      "在迭代 6000 次后， 训练损失为 0.00297459\n在迭代 6100 次后， 训练损失为 0.00286147",
      "\n在迭代 6200 次后， 训练损失为 0.00274884\n在迭代 6300 次后， 训练损失为 0.00263524\n在迭代 6400 次后， 训练损失为 0.00251788\n",
      "在迭代 6500 次后， 训练损失为 0.00244217\n在迭代 6600 次后， 训练损失为 0.00237561\n",
      "在迭代 6700 次后， 训练损失为 0.00230427\n在迭代 6800 次后， 训练损失为 0.00225139\n在迭代 6900 次后， 训练损失为 0.00221786\n在迭代 7000 次后， 训练损失为 0.0021837\n在迭代 7100 次后， 训练损失为 0.00214859\n",
      "在迭代 7200 次后， 训练损失为 0.00211286\n",
      "在迭代 7300 次后， 训练损失为 0.00207667\n在迭代 7400 次后， 训练损失为 0.00204028\n在迭代 7500 次后， 训练损失为 0.00200313\n在迭代 7600 次后， 训练损失为 0.00196321\n在迭代 7700 次后， 训练损失为 0.00192275",
      "\n",
      "在迭代 7800 次后， 训练损失为 0.00188195\n在迭代 7900 次后， 训练损失为 0.00184105\n在迭代 8000 次后， 训练损失为 0.00179786\n在迭代 8100 次后， 训练损失为 0.00175281\n",
      "在迭代 8200 次后， 训练损失为 0.00170704\n在迭代 8300 次后， 训练损失为 0.00166072",
      "\n在迭代 8400 次后， 训练损失为 0.00161375\n在迭代 8500 次后， 训练损失为 0.00156631\n在迭代 8600 次后， 训练损失为 0.0015185\n",
      "在迭代 8700 次后， 训练损失为 0.00147046\n",
      "在迭代 8800 次后， 训练损失为 0.00142301\n在迭代 8900 次后， 训练损失为 0.00137533\n在迭代 9000 次后， 训练损失为 0.00132818\n在迭代 9100 次后， 训练损失为 0.00128052\n在迭代 9200 次后， 训练损失为 0.00123037",
      "\n",
      "在迭代 9300 次后， 训练损失为 0.00118092\n在迭代 9400 次后， 训练损失为 0.00113142\n在迭代 9500 次后， 训练损失为 0.00108256\n",
      "在迭代 9600 次后， 训练损失为 0.00103177\n",
      "在迭代 9700 次后， 训练损失为 0.000997055\n在迭代 9800 次后， 训练损失为 0.000984017\n在迭代 9900 次后， 训练损失为 0.00097067\n在迭代 10000 次后， 训练损失为 0.000957028",
      "\n",
      "在迭代 10100 次后， 训练损失为 0.000943122\n在迭代 10200 次后， 训练损失为 0.000928936\n在迭代 10300 次后， 训练损失为 0.000914507\n在迭代 10400 次后， 训练损失为 0.000899855\n",
      "在迭代 10500 次后， 训练损失为 0.000885015\n",
      "在迭代 10600 次后， 训练损失为 0.00087015\n在迭代 10700 次后， 训练损失为 0.000855103",
      "\n",
      "在迭代 10800 次后， 训练损失为 0.000840033\n在迭代 10900 次后， 训练损失为 0.000825027\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 10\n",
    "w1 = tf.Variable(tf.random_normal([2, 3], stddev=1, seed=1))\n",
    "w2 = tf.Variable(tf.random_normal([3, 1], stddev=1, seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "a = tf.nn.relu(tf.matmul(x, w1))\n",
    "yhat = tf.nn.relu(tf.matmul(a, w2))\n",
    "\n",
    "cross_entropy = -tf.reduce_mean(y * tf.log(tf.clip_by_value(yhat, 1e-10, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "rdm = RandomState(1)\n",
    "data_size = 516\n",
    "X = rdm.rand(data_size, 2)\n",
    "Y = [[int(x1 + x2 < 1)] for (x1, x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w1))\n",
    "    print(sess.run(w2))\n",
    "    \n",
    "    steps = 11000\n",
    "    for i in range(steps):\n",
    "        start = i * batch_size % data_size\n",
    "        end = min(start + batch_size, data_size)\n",
    "        sess.run(train_step, feed_dict={x: X[start: end], y: Y[start: end]})\n",
    "        if i % 100 == 0:\n",
    "            training_loss = sess.run(cross_entropy, feed_dict={x: X, y: Y})\n",
    "            print('在迭代 %d 次后， 训练损失为 %g' % (i, training_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\nW0913 16:06:37.225303 12840 deprecation.py:323] From <ipython-input-1-20d90f837d76>:3: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0913 16:06:37.247242 12840 deprecation.py:323] From d:\\program files\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease write your own downloading logic.\n",
      "W0913 16:06:37.250234 12840 deprecation.py:323] From d:\\program files\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n",
      "W0913 16:06:38.376224 12840 deprecation.py:323] From d:\\program files\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.data to implement this functionality.\n",
      "W0913 16:06:38.417117 12840 deprecation.py:323] From d:\\program files\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use tf.one_hot on tensors.\n",
      "W0913 16:06:38.578686 12840 deprecation.py:323] From d:\\program files\\python37\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Extracting D:\\tmp\\mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting D:\\tmp\\mnist\\train-labels-idx1-ubyte.gz\nExtracting D:\\tmp\\mnist\\t10k-images-idx3-ubyte.gz\nExtracting D:\\tmp\\mnist\\t10k-labels-idx1-ubyte.gz\n",
      "training data size:  55000\nvalidating data size:  5000\ntest data size:  10000\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('D:\\\\tmp\\\\mnist', one_hot=True)\n",
    "print('training data size: ', mnist.train.num_examples)\n",
    "print('validating data size: ', mnist.validation.num_examples)\n",
    "print('test data size: ', mnist.test.num_examples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cifar10_folder = 'D:\\\\tmp\\\\cifar10'\n",
    "\n",
    "train_datasets = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5',]\n",
    "test_dataset = ['test_batch']\n",
    "\n",
    "c10_image_height = 32\n",
    "c10_image_width = 32\n",
    "c10_image_depth = 3\n",
    "c10_num_labels = 10\n",
    "c10_image_size = 32\n",
    "\n",
    "with open(cifar10_folder + test_dataset[0], 'rb') as f0:\n",
    "    c10_test_dict = pickle.load(f0, encoding='bytes')\n",
    "\n",
    "c10_test_dataset, c10_test_labels = c10_test_dict[b'data'], c10_test_dict[b'labels']\n",
    "test_dataset_cifar10, test_labels_cifar10 = reformat_data(c10_test_dataset, c10_test_labels, c10_image_size, c10_image_size, c10_image_depth)\n",
    "\n",
    "\n",
    "c10_train_dataset, c10_train_labels = [], []\n",
    "\n",
    "\n",
    "\n",
    "for\n",
    " train_dataset \n",
    "in\n",
    " train_datasets:\n",
    "\n",
    "    \n",
    "with\n",
    " open(cifar10_folder + train_dataset, \n",
    "'rb'\n",
    ") \n",
    "as\n",
    " f0:\n",
    "\n",
    "        c10_train_dict = pickle.load(f0, encoding=\n",
    "'bytes'\n",
    ")\n",
    "\n",
    "        c10_train_dataset_, c10_train_labels_ = c10_train_dict[b\n",
    "'data'\n",
    "], c10_train_dict[b\n",
    "'labels'\n",
    "]\n",
    "\n",
    "\n",
    "        c10_train_dataset.append(c10_train_dataset_)\n",
    "\n",
    "        c10_train_labels += c10_train_labels_\n",
    "\n",
    "\n",
    "c10_train_dataset = np.concatenate(c10_train_dataset, axis=\n",
    "0\n",
    ")\n",
    "\n",
    "train_dataset_cifar10, train_labels_cifar10 = reformat_data(c10_train_dataset, c10_train_labels, c10_image_size, c10_image_size, c10_image_depth)\n",
    "\n",
    "del\n",
    " c10_train_dataset\n",
    "\n",
    "del\n",
    " c10_train_labels\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print\n",
    "(\n",
    "\"训练集包含以下标签: {}\"\n",
    ".format(np.unique(c10_train_dict[b\n",
    "'labels'\n",
    "])))\n",
    "\n",
    "print\n",
    "(\n",
    "'训练集维度'\n",
    ", train_dataset_cifar10.shape, train_labels_cifar10.shape)\n",
    "\n",
    "print\n",
    "(\n",
    "'测试集维度'\n",
    ", test_dataset_cifar10.shape, test_labels_cifar10.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}